{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NB4lO-GZEgkP"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "ywmqYQBxHqgQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "IGUcI4HMH5cz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BraKqM5EIM2k",
        "outputId": "bcabc156-c6a8-4c66-f517-2bdcb9a1253d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMnfDyXaIqmB",
        "outputId": "f103f921-ca17-47b7-c22e-997deaa90f6c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#input to text summarize\n",
        "text = \"\"\" LLM stands for large language models, like OpenAI‚Äôs ChatGPT and Google‚Äôs Bard. LLMs are, almost always, a very big neural network that takes natural language texts as input, and outputs some other natural language texts.\n",
        "\n",
        "But how large is large? The ‚Äúlargeness‚Äù of a model is usually measured by the number of parameters it contains. And the largest known model (as of Feb 2023) is Google‚Äôs PaLM with 540 billion parameters.\n",
        "Pre-LLM\n",
        "\n",
        "Rome wasn't built in a day, neither are LLMs. There has been quite a development process for LLMs, starting from Word2vec.\n",
        "Word2vec\n",
        "\n",
        "Many ML practitioners have used word2vec (word-to-vector) before. First proposed in 2013, word2vec can transform each word in the input dataset to a vector (a list of float numbers), therefore converting texts into numbers. More amazingly, the converted vectors can actually capture the semantic relevance of the words. The most famous example to illustrate is ‚Äúking‚Äù - ‚Äúman‚Äù + ‚Äúwoman‚Äù ~= ‚Äúqueen‚Äù (source). \"\"\""
      ],
      "metadata": {
        "id": "WCY8CACkI9Mq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the text\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "xGE4JdecJb-H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating freq table to keep score of each word\n",
        "\n",
        "freqtable = dict()\n",
        "for word in words:\n",
        "   word = word.lower()\n",
        "   if word in stopwords:\n",
        "     continue\n",
        "   if word in freqtable:\n",
        "    freqtable[word] +=1\n",
        "   else:\n",
        "    freqtable[word] =1"
      ],
      "metadata": {
        "id": "SdtXELEmKtSh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating freq table to keep score of each sentences\n",
        "sentences = sent_tokenize(text)\n",
        "sentencevalue = dict()\n",
        "for sentence in sentences:\n",
        "  for word, freq in freqtable.items():\n",
        "    if word in sentence.lower():\n",
        "      if sentence in sentencevalue:\n",
        "         sentencevalue[sentence] += freq\n",
        "      else:\n",
        "         sentencevalue[sentence] = freq\n",
        "\n",
        "sumValues = 0\n",
        "for sentence in sentencevalue:\n",
        "  sumValues += sentencevalue[sentence]"
      ],
      "metadata": {
        "id": "lIldvhr_L9ZY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average = int(sumValues/len(sentencevalue))"
      ],
      "metadata": {
        "id": "ZBQWOe3DUFA8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = ''\n",
        "for sentence in sentences:\n",
        "  if (sentence in sentencevalue) and (sentencevalue[sentence]) > (1.2*average):\n",
        "    summary += \"\" + sentence\n",
        ""
      ],
      "metadata": {
        "id": "e2XxQGNvVVke"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"original text :\\n\\n\",text)\n",
        "print(\" \")\n",
        "print(\"len of od text :\",len(text))"
      ],
      "metadata": {
        "id": "VWnooRvPlpx7",
        "outputId": "f5fdeb76-8365-4bd5-95f0-ab61952661c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original text :\n",
            "\n",
            "  LLM stands for large language models, like OpenAI‚Äôs ChatGPT and Google‚Äôs Bard. LLMs are, almost always, a very big neural network that takes natural language texts as input, and outputs some other natural language texts.\n",
            "\n",
            "But how large is large? The ‚Äúlargeness‚Äù of a model is usually measured by the number of parameters it contains. And the largest known model (as of Feb 2023) is Google‚Äôs PaLM with 540 billion parameters.\n",
            "Pre-LLM\n",
            "\n",
            "Rome wasn't built in a day, neither are LLMs. There has been quite a development process for LLMs, starting from Word2vec.\n",
            "Word2vec\n",
            "\n",
            "Many ML practitioners have used word2vec (word-to-vector) before. First proposed in 2013, word2vec can transform each word in the input dataset to a vector (a list of float numbers), therefore converting texts into numbers. More amazingly, the converted vectors can actually capture the semantic relevance of the words. The most famous example to illustrate is ‚Äúking‚Äù - ‚Äúman‚Äù + ‚Äúwoman‚Äù ~= ‚Äúqueen‚Äù (source). \n",
            " \n",
            "len of od text : 975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"‚ù§Ô∏èSummarizes textüòç :\\n\\n\",summary)\n",
        "print(\" \")\n",
        "print(\"Length of summary :\",len(summary))"
      ],
      "metadata": {
        "id": "BEi9RfEzmDu0",
        "outputId": "a20066b8-170e-4f1e-ab62-7b0654df0edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ù§Ô∏èSummarizes textüòç :\n",
            "\n",
            " LLMs are, almost always, a very big neural network that takes natural language texts as input, and outputs some other natural language texts.First proposed in 2013, word2vec can transform each word in the input dataset to a vector (a list of float numbers), therefore converting texts into numbers.\n",
            " \n",
            "Length of summary : 298\n"
          ]
        }
      ]
    }
  ]
}